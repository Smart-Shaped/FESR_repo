ml:
  spark:
    app:
      name: "ml-application"
    yarn:
      am:
        cores: 1
        memory: "1G"
    driver:
      memory: "1G"
      cores: 1
    executor:
      memory: "2G"
      instances: 2
      cores: 2
    serializer: "org.apache.spark.serializer.KryoSerializer"
    sql:
      parquet:
        compression:
          codec: "zstd"
    hadoop:
      fs:
        defaultFS: "hdfs://namenode:8020"
      parquet:
        page:
          size:
            row:
              check:
                min: 2
                max: 10
      dfs:
        replication: 1
    cassandra:
      connection:
        host: "cassandra1"
        port: "9042"
  hdfs:
    modelDir: "/user/spark/model"
    readers:
      default: ""
      reader1:
        class: "com.smartshaped.smartfesr.ml.CustomHdfsReader"
        path: "/user/spark/topic1/data.parquet"
      reader2:
        class: "com.smartshaped.smartfesr.ml.CustomHdfsReader"
        path: "/user/spark/checkpoint/topic2"
  pipeline:
    class: "com.smartshaped.fesr.ml.CustomPipeline"
  modelSaver:
    class: "com.smartshaped.fesr.ml.CustomModelSaver"
  cassandra:
    model:
      class: "com.smartshaped.smartfesr.ml.models.CustomModel"
    datacenter: "datacenter1"
    keyspace:
      name: "ml_keyspace"
      replication_factor: 1
